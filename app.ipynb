{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8070d984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ENG CHANDRAKANT\\AppData\\Local\\Temp\\ipykernel_14960\\3149373741.py:5: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a type of artificial neural network architecture that combines the strengths of large language models (LLMs) with the power of chain-of-thought reasoning. It's a relatively new concept in machine learning, introduced in 2022, and has been gaining attention in the research community.\n",
      "\n",
      "**The idea behind LangChain:**\n",
      "\n",
      "LangChain is designed to address the limitations of traditional language models, which are excellent at generating text but often struggle with complex, multi-step reasoning tasks. The key insight is to leverage the strengths of LLMs in understanding natural language and generating text, while also incorporating the ability to perform chain-of-thought reasoning, which involves breaking down complex problems into a series of simpler, more manageable steps.\n",
      "\n",
      "**How LangChain works:**\n",
      "\n",
      "A LangChain model consists of two main components:\n",
      "\n",
      "1. **Language Model (LM)**: A large, pre-trained language model (e.g., transformer-based models like BERT, RoBERTa, or XLNet) that generates text based on input prompts.\n",
      "2. **Chain-of-Thought (CoT) Module**: A neural network module that takes the output from the LM and applies a series of reasoning steps to arrive at a final answer. The CoT module is designed to mimic human-like reasoning, where each step builds upon the previous one to solve a complex problem.\n",
      "\n",
      "The LangChain architecture works as follows:\n",
      "\n",
      "* The input prompt is fed into the LM, which generates an initial response.\n",
      "* The CoT module takes the LM's output and applies a series of reasoning steps, using the generated text as input for each step.\n",
      "* Each step in the CoT module involves generating a new piece of text that builds upon the previous step, effectively creating a chain of thought.\n",
      "* The final output is generated by the last step in the CoT module.\n",
      "\n",
      "**Benefits of LangChain:**\n",
      "\n",
      "LangChain has several advantages over traditional language models:\n",
      "\n",
      "* **Improved reasoning capabilities**: LangChain can perform complex, multi-step reasoning tasks, which are challenging for traditional LLMs.\n",
      "* **Increased interpretability**: The chain-of-thought approach provides a more transparent and interpretable way of arriving at a solution, making it easier to understand the model's decision-making process.\n",
      "* **Flexibility and adaptability**: LangChain can be applied to a wide range of tasks, including question answering, text generation, and decision-making.\n",
      "\n",
      "While LangChain is still a relatively new concept, it has the potential to significantly advance the field of natural language processing and artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=os.getenv(\"TOGETHER_API_KEY\"),\n",
    "    openai_api_base=\"https://api.together.xyz/v1\",\n",
    "    model=\"meta-llama/Llama-3-70b-chat-hf\"\n",
    ")\n",
    "\n",
    "result = llm.invoke(\"What is LangChain in machine learning?\")\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84eea881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ChatBot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ENG CHANDRAKANT\\AppData\\Local\\Temp\\ipykernel_14960\\2036458690.py:63: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  vector_db = Chroma(persist_directory=db_path, embedding_function=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2'))\n",
      "C:\\Users\\ENG CHANDRAKANT\\AppData\\Local\\Temp\\ipykernel_14960\\2036458690.py:63: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_db = Chroma(persist_directory=db_path, embedding_function=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2'))\n",
      "C:\\Users\\ENG CHANDRAKANT\\AppData\\Local\\Temp\\ipykernel_14960\\2036458690.py:73: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": user_input})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot: Based on the context provided, it's important to clarify that feeling depressed and having depression are not exactly the same thing. Depression is a diagnosable disorder characterized by pervasive physical symptoms such as sleep and appetite disturbance, and changes in brain chemistry. \n",
      "\n",
      "Feeling depressed, on the other hand, can be a normal emotional response to difficult circumstances, such as chronic adversity, loss, or low self-esteem. While it's understandable to feel overwhelmed and unhappy, it's essential to recognize that this emotional state can be addressed and managed with support and interventions.\n",
      "\n",
      "If you're feeling depressed, it's crucial to reach out to a mental health professional or a trusted adult for guidance and support. They can help you identify the underlying causes of your emotional distress and develop strategies to cope with your feelings.\n",
      "\n",
      "Remember, you're not alone, and there is help available.\n",
      "ChatBot: Take care of yourself. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def initialize_llm():\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        openai_api_key=os.getenv(\"TOGETHER_API_KEY\"),  # safer: use env variable\n",
    "        openai_api_base=\"https://api.together.xyz/v1\",\n",
    "        model=\"meta-llama/Llama-3-70b-chat-hf\"\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "def create_vector_db():\n",
    "    loader = DirectoryLoader(\n",
    "        \"data\",\n",
    "        glob='*.pdf',\n",
    "        loader_cls=PyPDFLoader\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name='sentence-transformers/all-MiniLM-L6-v2'\n",
    "    )\n",
    "    vector_db = Chroma.from_documents(\n",
    "        texts, \n",
    "        embeddings, \n",
    "        persist_directory='./chroma_db'\n",
    "    )\n",
    "    print(\"Chroma DB created and data saved\")\n",
    "    return vector_db\n",
    "\n",
    "def setup_qa_chain(vector_db, llm):\n",
    "    retriever = vector_db.as_retriever()\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"Use the following context to answer the question.\\nContext: {context}\\nQuestion: {question}\\nAnswer:\"\n",
    "    )\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "    return qa_chain\n",
    "\n",
    "def main():\n",
    "    print(\"Initializing ChatBot...\")\n",
    "    llm = initialize_llm()\n",
    "\n",
    "    db_path = \"chroma_db\"\n",
    "\n",
    "    if not os.path.exists(db_path):\n",
    "        vector_db = create_vector_db()\n",
    "    else:\n",
    "        vector_db = Chroma(persist_directory=db_path, embedding_function=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2'))\n",
    "\n",
    "    qa_chain = setup_qa_chain(vector_db, llm)\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Enter your question: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"ChatBot: Take care of yourself. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        result = qa_chain({\"query\": user_input})\n",
    "        print(\"ChatBot:\", result.get(\"result\", \"\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a449ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ChatBot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ENG CHANDRAKANT\\anaconda3\\Lib\\site-packages\\gradio\\chat_interface.py:339: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://5b28030b0216be2ac6.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5b28030b0216be2ac6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Loads from .env file\n",
    "\n",
    "def initialize_llm():\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    \n",
    "    together_api_key = os.getenv(\"TOGETHER_API_KEY\")  # Load from .env file\n",
    "    if not together_api_key:\n",
    "        raise ValueError(\"TOGETHER_API_KEY not found in environment variables\")\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0.7,\n",
    "        openai_api_key=together_api_key,\n",
    "        openai_api_base=\"https://api.together.xyz/v1\",\n",
    "        model=\"meta-llama/Llama-3-70b-chat-hf\"\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "# Create vector database function\n",
    "def create_vector_db():\n",
    "    loader = DirectoryLoader(\n",
    "        \"data\",\n",
    "        glob='*.pdf',\n",
    "        loader_cls=PyPDFLoader\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name='sentence-transformers/all-MiniLM-L6-v2'\n",
    "    )\n",
    "    vector_db = Chroma.from_documents(\n",
    "        texts, \n",
    "        embeddings, \n",
    "        persist_directory='./chroma_db'\n",
    "    )\n",
    "    print(\"Chroma DB created and data saved\")\n",
    "    return vector_db\n",
    "\n",
    "# Setup QA chain function\n",
    "def setup_qa_chain(vector_db, llm):\n",
    "    retriever = vector_db.as_retriever()\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "        Respond compassionately to emotional queries. Provide helpful information.\n",
    "        If the question indicates distress, offer support resources.\n",
    "        \n",
    "        Context: {context}\n",
    "        Question: {question}\n",
    "        \n",
    "        Answer:\n",
    "        \"\"\"\n",
    "    )\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "    return qa_chain\n",
    "\n",
    "# Initialize components\n",
    "print(\"Initializing ChatBot...\")\n",
    "llm = initialize_llm()\n",
    "\n",
    "db_path = \"chroma_db\"\n",
    "if not os.path.exists(db_path):\n",
    "    vector_db = create_vector_db()\n",
    "else:\n",
    "    vector_db = Chroma(\n",
    "        persist_directory=db_path,\n",
    "        embedding_function=HuggingFaceEmbeddings(\n",
    "            model_name='sentence-transformers/all-MiniLM-L6-v2'\n",
    "        )\n",
    "    )\n",
    "\n",
    "qa_chain = setup_qa_chain(vector_db, llm)\n",
    "\n",
    "# Modern Mental Health CSS\n",
    "custom_css = \"\"\"\n",
    "@import url('https://fonts.googleapis.com/css2?family=Nunito:wght@300;400;600;700&display=swap');\n",
    "\n",
    ":root {\n",
    "    --primary-gradient: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "    --secondary-gradient: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); \n",
    "    --healing-gradient: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);\n",
    "    --warm-gradient: linear-gradient(135deg, #fa709a 0%, #fee140 100%);\n",
    "    --glass-bg: rgba(255, 255, 255, 0.25);\n",
    "    --glass-border: rgba(255, 255, 255, 0.3);\n",
    "    --text-primary: #2d3748;\n",
    "    --text-light: #4a5568;\n",
    "    --shadow-soft: 0 8px 32px rgba(31, 38, 135, 0.37);\n",
    "    --shadow-glow: 0 0 30px rgba(102, 126, 234, 0.3);\n",
    "}\n",
    "\n",
    "* {\n",
    "    font-family: 'Nunito', sans-serif !important;\n",
    "}\n",
    "\n",
    ".gradio-container {\n",
    "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "    min-height: 100vh;\n",
    "    position: relative;\n",
    "}\n",
    "\n",
    "/* Remove unnecessary animations */\n",
    "@keyframes float {\n",
    "    0%, 100% { transform: translateY(0px); }\n",
    "    50% { transform: translateY(-5px); }\n",
    "}\n",
    "\n",
    "@keyframes pulse {\n",
    "    0%, 100% { opacity: 1; }\n",
    "    50% { opacity: 0.8; }\n",
    "}\n",
    "\n",
    ".chatbot {\n",
    "    background: var(--glass-bg) !important;\n",
    "    backdrop-filter: blur(20px) !important;\n",
    "    border: 1px solid var(--glass-border) !important;\n",
    "    border-radius: 24px !important;\n",
    "    box-shadow: var(--shadow-soft) !important;\n",
    "    overflow: hidden !important;\n",
    "    position: relative !important;\n",
    "}\n",
    "\n",
    ".chatbot::before {\n",
    "    content: '';\n",
    "    position: absolute;\n",
    "    top: 0;\n",
    "    left: 0;\n",
    "    right: 0;\n",
    "    height: 4px;\n",
    "    background: var(--healing-gradient);\n",
    "    z-index: 1;\n",
    "}\n",
    "\n",
    ".message.user {\n",
    "    background: var(--primary-gradient) !important;\n",
    "    color: white !important;\n",
    "    border-radius: 20px 20px 4px 20px !important;\n",
    "    margin-left: auto !important;\n",
    "    max-width: 75% !important;\n",
    "    padding: 16px 20px !important;\n",
    "    font-weight: 500 !important;\n",
    "    box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4) !important;\n",
    "    border: none !important;\n",
    "    position: relative !important;\n",
    "    display: flex !important;\n",
    "    align-items: center !important;\n",
    "    gap: 12px !important;\n",
    "}\n",
    "\n",
    ".message.bot {\n",
    "    background: rgba(255, 255, 255, 0.98) !important;\n",
    "    color: #1a202c !important;\n",
    "    border-radius: 20px 20px 20px 4px !important;\n",
    "    box-shadow: 0 4px 20px rgba(0, 0, 0, 0.2) !important;\n",
    "    max-width: 75% !important;\n",
    "    padding: 16px 20px !important;\n",
    "    border: 1px solid rgba(255, 255, 255, 0.6) !important;\n",
    "    line-height: 1.6 !important;\n",
    "    position: relative !important;\n",
    "    backdrop-filter: blur(10px) !important;\n",
    "    display: flex !important;\n",
    "    align-items: flex-start !important;\n",
    "    gap: 12px !important;\n",
    "}\n",
    "\n",
    "/* Ensure all chatbot content is visible */\n",
    ".chatbot .message.bot,\n",
    ".chatbot .message.bot p,\n",
    ".chatbot .message.bot div,\n",
    ".chatbot .message.bot span,\n",
    ".chatbot .message.bot ul,\n",
    ".chatbot .message.bot li,\n",
    ".chatbot .message.bot strong,\n",
    ".chatbot .message.bot em {\n",
    "    color: #1a202c !important;\n",
    "    font-weight: 500 !important;\n",
    "}\n",
    "\n",
    ".chatbot .message.bot {\n",
    "    background: white !important;\n",
    "    border: 2px solid rgba(102, 126, 234, 0.2) !important;\n",
    "}\n",
    "\n",
    ".message.bot p {\n",
    "    margin-bottom: 12px !important;\n",
    "    color: #1a202c !important;\n",
    "    font-weight: 500 !important;\n",
    "}\n",
    "\n",
    ".message.bot ul {\n",
    "    padding-left: 20px !important;\n",
    "    color: #2d3748 !important;\n",
    "}\n",
    "\n",
    ".message.bot li {\n",
    "    margin-bottom: 6px !important;\n",
    "    color: #2d3748 !important;\n",
    "}\n",
    "\n",
    ".message.bot * {\n",
    "    color: #1a202c !important;\n",
    "}\n",
    "\n",
    "/* Input styling */\n",
    ".input-container {\n",
    "    background: var(--glass-bg) !important;\n",
    "    backdrop-filter: blur(15px) !important;\n",
    "    border-radius: 20px !important;\n",
    "    border: 1px solid var(--glass-border) !important;\n",
    "    box-shadow: var(--shadow-soft) !important;\n",
    "}\n",
    "\n",
    "textarea {\n",
    "    background: transparent !important;\n",
    "    color: white !important;\n",
    "    border: none !important;\n",
    "    font-size: 16px !important;\n",
    "    font-weight: 400 !important;\n",
    "    resize: none !important;\n",
    "}\n",
    "\n",
    "textarea::placeholder {\n",
    "    color: rgba(255, 255, 255, 0.7) !important;\n",
    "}\n",
    "\n",
    "/* Button styling */\n",
    "button {\n",
    "    background: var(--healing-gradient) !important;\n",
    "    border: none !important;\n",
    "    border-radius: 12px !important;\n",
    "    color: white !important;\n",
    "    font-weight: 600 !important;\n",
    "    padding: 12px 24px !important;\n",
    "    transition: all 0.3s ease !important;\n",
    "    box-shadow: 0 4px 15px rgba(79, 172, 254, 0.4) !important;\n",
    "}\n",
    "\n",
    "button:hover {\n",
    "    transform: translateY(-2px) !important;\n",
    "    box-shadow: 0 6px 25px rgba(79, 172, 254, 0.6) !important;\n",
    "}\n",
    "\n",
    "/* Example buttons */\n",
    ".examples button {\n",
    "    background: rgba(255, 255, 255, 0.1) !important;\n",
    "    border: 1px solid rgba(255, 255, 255, 0.2) !important;\n",
    "    border-radius: 16px !important;\n",
    "    color: white !important;\n",
    "    padding: 10px 16px !important;\n",
    "    margin: 4px !important;\n",
    "    font-size: 14px !important;\n",
    "    backdrop-filter: blur(10px) !important;\n",
    "    transition: all 0.3s ease !important;\n",
    "}\n",
    "\n",
    ".examples button:hover {\n",
    "    background: rgba(255, 255, 255, 0.2) !important;\n",
    "    transform: translateY(-1px) !important;\n",
    "    box-shadow: 0 4px 15px rgba(255, 255, 255, 0.1) !important;\n",
    "}\n",
    "\n",
    "/* Avatar styling */\n",
    ".avatar {\n",
    "    flex-shrink: 0 !important;\n",
    "    width: 32px !important;\n",
    "    height: 32px !important;\n",
    "    border-radius: 50% !important;\n",
    "    overflow: hidden !important;\n",
    "    border: 2px solid rgba(255, 255, 255, 0.8) !important;\n",
    "    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.2) !important;\n",
    "}\n",
    "\n",
    ".avatar img {\n",
    "    width: 100% !important;\n",
    "    height: 100% !important;\n",
    "    object-fit: cover !important;\n",
    "    border-radius: 50% !important;\n",
    "}\n",
    "\n",
    "/* Header styling */\n",
    "h1 {\n",
    "    color: white !important;\n",
    "    text-shadow: 0 2px 10px rgba(0, 0, 0, 0.3) !important;\n",
    "    font-weight: 700 !important;\n",
    "    font-size: 2.5rem !important;\n",
    "}\n",
    "\n",
    "p {\n",
    "    color: rgba(255, 255, 255, 0.9) !important;\n",
    "    text-shadow: 0 1px 3px rgba(0, 0, 0, 0.3) !important;\n",
    "    font-weight: 400 !important;\n",
    "    font-size: 1.1rem !important;\n",
    "}\n",
    "\n",
    "/* Remove footer */\n",
    "footer {\n",
    "    display: none !important;\n",
    "}\n",
    "\n",
    "/* Scrollbar styling */\n",
    "::-webkit-scrollbar {\n",
    "    width: 8px;\n",
    "}\n",
    "\n",
    "::-webkit-scrollbar-track {\n",
    "    background: rgba(255, 255, 255, 0.1);\n",
    "    border-radius: 4px;\n",
    "}\n",
    "\n",
    "::-webkit-scrollbar-thumb {\n",
    "    background: var(--healing-gradient);\n",
    "    border-radius: 4px;\n",
    "}\n",
    "\n",
    "::-webkit-scrollbar-thumb:hover {\n",
    "    background: var(--primary-gradient);\n",
    "}\n",
    "\n",
    "/* Loading animation */\n",
    ".loading {\n",
    "    position: relative;\n",
    "}\n",
    "\n",
    ".loading::after {\n",
    "    content: '';\n",
    "    position: absolute;\n",
    "    top: 50%;\n",
    "    left: 50%;\n",
    "    width: 20px;\n",
    "    height: 20px;\n",
    "    margin: -10px 0 0 -10px;\n",
    "    border: 2px solid rgba(79, 172, 254, 0.3);\n",
    "    border-top: 2px solid #4facfe;\n",
    "    border-radius: 50%;\n",
    "    animation: spin 1s linear infinite;\n",
    "}\n",
    "\n",
    "@keyframes spin {\n",
    "    0% { transform: rotate(0deg); }\n",
    "    100% { transform: rotate(360deg); }\n",
    "}\n",
    "\n",
    "/* Mobile responsiveness */\n",
    "@media (max-width: 768px) {\n",
    "    .message.user, .message.bot {\n",
    "        max-width: 90% !important;\n",
    "        padding: 12px 16px !important;\n",
    "    }\n",
    "    \n",
    "    h1 {\n",
    "        font-size: 2rem !important;\n",
    "    }\n",
    "    \n",
    "    .chatbot {\n",
    "        border-radius: 16px !important;\n",
    "        margin: 10px !important;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def chatbot_response(message, history):\n",
    "    if not message.strip():\n",
    "        return \"Please enter a valid message\"\n",
    "    \n",
    "    try:\n",
    "        result = qa_chain({\"query\": message})\n",
    "        response = result.get(\"result\", \"I couldn't generate a response.\")\n",
    "        \n",
    "        if any(word in message.lower() for word in [\"depressed\", \"sad\", \"suicide\", \"anxious\"]):\n",
    "            response += \"\"\"\n",
    "            \\n\\n💜 If you're in distress, please consider contacting:\n",
    "            - National Suicide Prevention Lifeline: 988 (US)\n",
    "            - Crisis Text Line: Text HOME to 741741 (US)\n",
    "            \"\"\"\n",
    "            \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return \"Sorry, I encountered an error processing your request.\"\n",
    "\n",
    "# Create Gradio interface with modern anime theme\n",
    "with gr.Blocks(css=custom_css, theme=gr.themes.Default(primary_hue=\"violet\")) as app:\n",
    "    # Set favicon via HTML head\n",
    "    app.title = \"Anime Mental Health Companion\"\n",
    "    app.head = \"\"\"<link rel=\"icon\" href=\"https://i.imgur.com/3L8JQ2x.png\">\"\"\"\n",
    "    \n",
    "    with gr.Row():\n",
    "        gr.Markdown(\"\"\"\n",
    "        <div style=\"text-align: center; margin-bottom: 30px;\">\n",
    "            <h1>🌸 Mental Health Companion 🌸</h1>\n",
    "            <p>Your supportive AI wellness companion</p>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "    \n",
    "    # Using the modern ChatInterface format\n",
    "    chat_interface = gr.ChatInterface(\n",
    "        fn=chatbot_response,\n",
    "        examples=[\n",
    "            [\"I'm feeling really anxious today 😰\"],\n",
    "            [\"How can I practice mindfulness?\"],\n",
    "            [\"What are some self-care tips?\"],\n",
    "            [\"I'm having trouble sleeping\"],\n",
    "            [\"How do I deal with stress?\"]\n",
    "        ],\n",
    "        additional_inputs=None,\n",
    "        title=\"\",\n",
    "        description=\"\"\n",
    "    )\n",
    "    \n",
    "    # Workaround for avatars in newer Gradio versions\n",
    "    chat_interface.chatbot.avatar_images = [\n",
    "        (\"https://cdn3.iconfinder.com/data/icons/web-design-and-development-2-6/512/87-1024.png\", \"user\"),\n",
    "        (\"https://static.vecteezy.com/system/resources/previews/010/054/157/non_2x/chat-bot-robot-avatar-in-circle-round-shape-isolated-on-white-background-stock-illustration-ai-technology-futuristic-helper-communication-conversation-concept-in-flat-style-vector.jpg\", \"bot\")\n",
    "    ]\n",
    "\n",
    "# Launch without deprecated parameters\n",
    "app.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de946a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
